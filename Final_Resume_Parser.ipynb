{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b60941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import io\n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import constants as cs\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "import docx2txt\n",
    "import subprocess\n",
    "import docxpy\n",
    "import glob\n",
    "import numpy as np\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2919775a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'constants' from 'C:\\\\Users\\\\Moin Dalvi\\\\Data_Science\\\\Projects\\\\Resume_Classification\\\\constants.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e993a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR INDIAN RESUME RUN THE BELOW FUNCTION TO EXTRACT MOBILE NUMBER\n",
    "def extract_mobile_number(text):\n",
    "    phone= re.findall(r'[8-9]{1}[0-9]{9}',text)\n",
    "    \n",
    "    if len(phone) > 10:\n",
    "        return '+' + phone\n",
    "    else:\n",
    "        return phone\n",
    "\n",
    "def extract_email(text):\n",
    "        email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", text)\n",
    "        if email:\n",
    "            try:\n",
    "                return email[0].split()[0].strip(';')\n",
    "            except IndexError:\n",
    "                return None\n",
    "\n",
    "# Function to remove punctuation and tokenize the text\n",
    "def tokenText(extText):\n",
    "   \n",
    "    # Remove punctuation marks\n",
    "    punc = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
    "    for ele in extText:\n",
    "        if ele in punc:\n",
    "            puncText = extText.replace(ele, \"\")\n",
    "            \n",
    "    # Tokenize the text and remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    puncText.split()\n",
    "    word_tokens = word_tokenize(puncText)\n",
    "    TokenizedText = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    TokenizedText = []\n",
    "  \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            TokenizedText.append(w)\n",
    "    return(TokenizedText)            \n",
    "\n",
    "# Function to extract Name and contact details\n",
    "def extract_name(Text):\n",
    "    name = ''  \n",
    "    for i in range(0,3):\n",
    "        name = \" \".join([name, Text[i]])\n",
    "    return(name)\n",
    "\n",
    "# Grad all general stop words\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# Education Degrees\n",
    "EDUCATION = ['BE','B.E.', 'B.E', 'BS','B.S','B.Com','BCA','ME','M.E', 'M.E.', 'M.S','B.com','10','10+2','BTECH', 'B.TECH', 'M.TECH', 'MTECH', 'SSC', 'HSC', 'C.B.S.E','CBSE','ICSE', 'X', 'XII','10th','12th',' 10th',' 12th','Bachelor of Arts in Mathematics','Master of Science in Analytics','Bachelor of Business Administration','Major: Business Management']\n",
    "\n",
    "def extract_education(text):\n",
    "    nlp_text = nlp(text)\n",
    "\n",
    "    # Sentence Tokenizer\n",
    "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
    "\n",
    "\n",
    "    edu = {}\n",
    "    # Extract education degree\n",
    "    for index, t in enumerate(nlp_text):\n",
    "        for tex in t.split():\n",
    "            # Replace all special symbols\n",
    "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "            if tex in EDUCATION and tex not in STOPWORDS:\n",
    "                edu[tex] = t + nlp_text[index + 1]\n",
    "\n",
    "    # Extract year\n",
    "    education = []\n",
    "    for key in edu.keys():\n",
    "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
    "        if year:\n",
    "            education.append((key, ''.join(year[0])))\n",
    "        else:\n",
    "            education.append(key)\n",
    "    return education\n",
    "\n",
    "def extract_skills(resume_text):\n",
    "\n",
    "        nlp_text = nlp(resume_text)\n",
    "        noun_chunks = nlp_text.noun_chunks\n",
    "\n",
    "        # removing stop words and implementing word tokenization\n",
    "        tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "        \n",
    "        # reading the csv file\n",
    "        data = pd.read_csv(\"skills.csv\") \n",
    "        \n",
    "        # extract values\n",
    "        skills = list(data.columns.values)\n",
    "        \n",
    "        skillset = []\n",
    "        \n",
    "        # check for one-grams (example: python)\n",
    "        for token in tokens:\n",
    "            if token.lower() in skills:\n",
    "                skillset.append(token)\n",
    "        \n",
    "        # check for bi-grams and tri-grams (example: machine learning)\n",
    "        for token in noun_chunks:\n",
    "            token = token.text.lower().strip()\n",
    "            if token in skills:\n",
    "                skillset.append(token)\n",
    "        \n",
    "        return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
    "\n",
    "\n",
    "\n",
    "def string_found(string1, string2):\n",
    "        if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def extract_entity_sections_grad(text):\n",
    "    '''\n",
    "    Helper function to extract all the raw text from sections of resume specifically for \n",
    "    graduates and undergraduates\n",
    "    :param text: Raw text of resume\n",
    "    :return: dictionary of entities\n",
    "    '''\n",
    "    text_split = [i.strip() for i in text.split('\\n')]\n",
    "    entities = {}\n",
    "    key = False\n",
    "    for phrase in text_split:\n",
    "        if len(phrase) == 1:\n",
    "            p_key = phrase\n",
    "        else:\n",
    "            p_key = set(phrase.lower().split()) & set(cs.RESUME_SECTIONS_GRAD)\n",
    "        try:\n",
    "            p_key = list(p_key)[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        if p_key in cs.RESUME_SECTIONS_GRAD:\n",
    "            entities[p_key] = []\n",
    "            key = p_key\n",
    "        elif key and phrase.strip():\n",
    "            entities[key].append(phrase)\n",
    "    return entities \n",
    "\n",
    "# Function to extract experience details\n",
    "def expDetails(Text):\n",
    "    global sent\n",
    "   \n",
    "    Text = Text.split()\n",
    "   \n",
    "    for i in range(len(Text)-2):\n",
    "        Text[i].lower()\n",
    "        \n",
    "        if Text[i] ==  'years':\n",
    "            sent =  Text[i-2] + ' ' + Text[i-1] +' ' + Text[i] +' '+ Text[i+1] +' ' + Text[i+2]\n",
    "            l = re.findall('\\d*\\.?\\d+',sent)\n",
    "            for i in l:\n",
    "                a = float(i)\n",
    "            return(a)\n",
    "            return (sent)\n",
    "\n",
    "def extract_experience(resume_text):\n",
    "    '''\n",
    "    Helper function to extract experience from resume text\n",
    "    :param resume_text: Plain resume text\n",
    "    :return: list of experience\n",
    "    '''\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # word tokenization \n",
    "    word_tokens = nltk.word_tokenize(resume_text)\n",
    "\n",
    "    # remove stop words and lemmatize  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words and wordnet_lemmatizer.lemmatize(w) not in stop_words] \n",
    "    sent = nltk.pos_tag(filtered_sentence)\n",
    "\n",
    "    # parse regex\n",
    "    cp = nltk.RegexpParser('P: {<NNP>+}')\n",
    "    cs = cp.parse(sent)\n",
    "    \n",
    "    # for i in cs.subtrees(filter=lambda x: x.label() == 'P'):\n",
    "    #     print(i)\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    for vp in list(cs.subtrees(filter=lambda x: x.label()=='P')):\n",
    "        test.append(\" \".join([i[0] for i in vp.leaves() if len(vp.leaves()) >= 2]))\n",
    "\n",
    "    # Search the word 'experience' in the chunk and then print out the text after it\n",
    "    x = [x[x.lower().index('experience') + 10:] for i, x in enumerate(test) if x and 'experience' in x.lower()]\n",
    "    return x\n",
    "\n",
    "def string_found(string1, string2):\n",
    "        if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def get_score(_dict):\n",
    "    _len = len(_dict)\n",
    "    if _len >= 5:\n",
    "        return 1\n",
    "    elif _len < 5 and _len > 2:\n",
    "        return 0.5\n",
    "    elif _len  == 1:\n",
    "        return 0.2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def extract_competencies(text, experience_list):\n",
    "    '''\n",
    "    Helper function to extract competencies from resume text\n",
    "    :param resume_text: Plain resume text\n",
    "    :return: dictionary of competencies\n",
    "    '''\n",
    "    experience_text = ' '.join(experience_list)\n",
    "    competency_dict = {}\n",
    "    score = 0\n",
    "\n",
    "    percentage = (100 // len(cs.COMPETENCIES.keys()))\n",
    "\n",
    "    for competency in cs.COMPETENCIES.keys():\n",
    "        matches = {}\n",
    "        for item in cs.COMPETENCIES[competency]:\n",
    "            if string_found(item, experience_text):\n",
    "                if competency not in competency_dict.keys():\n",
    "                    match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
    "                    if item not in matches.keys():\n",
    "                        matches[item] = [match.group(0)]\n",
    "                    else:\n",
    "                        for i in match.groups():\n",
    "                            matches[item].append(i)    \n",
    "                    competency_dict[competency] = matches\n",
    "                else:\n",
    "                    match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
    "                    if item not in matches.keys():\n",
    "                        matches[item] = [match.group(0)]\n",
    "                    else:\n",
    "                        for i in match.groups():\n",
    "                            matches[item].append(i)\n",
    "                    competency_dict[competency] = matches\n",
    "                score += get_score(competency_dict[competency]) * percentage\n",
    "    \n",
    "    competency_dict['score'] = score \n",
    "    list=list(competency_dict.keys())\n",
    "    return(list)\n",
    "\n",
    "def extract_competencies_score(text, experience_list):\n",
    "        '''\n",
    "        Helper function to extract competencies from resume text\n",
    "        :param resume_text: Plain resume text\n",
    "        :return: dictionary of competencies\n",
    "        '''\n",
    "        experience_text = ' '.join(experience_list)\n",
    "        competency_dict = {}\n",
    "        score = 0\n",
    "\n",
    "        percentage = (100 // len(cs.COMPETENCIES.keys()))\n",
    "\n",
    "        for competency in cs.COMPETENCIES.keys():\n",
    "            matches = {}\n",
    "            for item in cs.COMPETENCIES[competency]:\n",
    "                if string_found(item, experience_text):\n",
    "                    if competency not in competency_dict.keys():\n",
    "                        match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
    "                        if item not in matches.keys():\n",
    "                            matches[item] = [match.group(0)]\n",
    "                        else:\n",
    "                            for i in match.groups():\n",
    "                                matches[item].append(i)    \n",
    "                        competency_dict[competency] = matches\n",
    "                    else:\n",
    "                        match = re.search(r'([^.|,]*' + item + '[^.|,]*)', experience_text)\n",
    "                        if item not in matches.keys():\n",
    "                            matches[item] = [match.group(0)]\n",
    "                        else:\n",
    "                            for i in match.groups():\n",
    "                                matches[item].append(i)\n",
    "                        competency_dict[competency] = matches\n",
    "                    score += get_score(competency_dict[competency]) * percentage\n",
    "        \n",
    "        competency_dict['score'] = score \n",
    "        return(competency_dict['score'])\n",
    "\n",
    "def extract_dob(text):\n",
    "        \n",
    "    result1=re.findall(r\"[\\d]{1,2}/[\\d]{1,2}/[\\d]{4}\",text)\n",
    "    result2=re.findall(r\"[\\d]{1,2}-[\\d]{1,2}-[\\d]{4}\",text)           \n",
    "    result3= re.findall(r\"[\\d]{1,2} [ADFJMNOSadfjmnos]\\w* [\\d]{4}\",text)\n",
    "    result4=re.findall(r\"([\\d]{1,2})\\.([\\d]{1,2})\\.([\\d]{4})\",text)\n",
    "                \n",
    "    l=[result1,result2,result3,result4]\n",
    "    for i in l:\n",
    "        if i==[]:\n",
    "            continue\n",
    "        else:\n",
    "            return i\n",
    "\n",
    "\n",
    "def extract_text_from_docx(path):\n",
    "    '''\n",
    "    Helper function to extract plain text from .docx files\n",
    "    :param doc_path: path to .docx file to be extracted\n",
    "    :return: string of extracted text\n",
    "    '''\n",
    "    try:\n",
    "        temp = docx2txt.process(path)\n",
    "        return temp\n",
    "    except KeyError:\n",
    "        return ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e158b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Name','Mobile No.', 'Email','DOB','Education Qualifications','Skills','Experience (Years)','Last Position','Competence','competence score'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a91ab3",
   "metadata": {},
   "source": [
    "### For Single Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7c3a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "path_input = r\"C:/Users\\Moin Dalvi\\Data_Science\\Projects\\Resume_Classification/Resumes_docx/Peoplesoft/Peoplesoft Admin_AnubhavSingh.docx\"\n",
    "if path_input.endswith('.docx'):\n",
    "    text = extract_text_from_docx(path_input)\n",
    "    tokText = tokenText(text)\n",
    "    df.loc[i,'Name']=extract_name(tokText)\n",
    "    df.loc[i,'Mobile No.']=extract_mobile_number(text)\n",
    "    df.loc[i,'Email']=extract_email(text)\n",
    "    df.loc[i,'DOB']=extract_dob(text)\n",
    "    df.loc[i,'Education Qualifications']=extract_education(text)\n",
    "    df.loc[i,'Skills']=extract_skills(text)\n",
    "    df.loc[i,'Experience (Years)']=expDetails(text) \n",
    "    experience_list1=extract_entity_sections_grad(text) \n",
    "\n",
    "    if 'experience' in experience_list1:\n",
    "        i=0\n",
    "        experience_list=experience_list1['experience']\n",
    "        df.loc[i,'Last Position']=extract_experience(text)\n",
    "        df.loc[i,'Competence']=extract_competencies(text,experience_list)\n",
    "        df.loc[i,'competence score']=extract_competencies_score(text,experience_list)\n",
    "\n",
    "    else:\n",
    "        df.loc[i,'Last Position']='NA'\n",
    "        df.loc[i,'Competence']='NA'\n",
    "        df.loc[i,'competence score']='NA'\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acea4d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Mobile No.</th>\n",
       "      <th>Email</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Education Qualifications</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Experience (Years)</th>\n",
       "      <th>Last Position</th>\n",
       "      <th>Competence</th>\n",
       "      <th>competence score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anubhav Kumar Singh</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[11/09/1990]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Servers, Installation, Ansible, Architecture,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[,  Installing Oracle Policy Automation]</td>\n",
       "      <td>(teamwork, leadership, score)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name Mobile No. Email           DOB  \\\n",
       "0   Anubhav Kumar Singh         []  None  [11/09/1990]   \n",
       "\n",
       "  Education Qualifications                                             Skills  \\\n",
       "0                       []  [Servers, Installation, Ansible, Architecture,...   \n",
       "\n",
       "  Experience (Years)                             Last Position  \\\n",
       "0               None  [,  Installing Oracle Policy Automation]   \n",
       "\n",
       "                      Competence competence score  \n",
       "0  (teamwork, leadership, score)              8.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae16a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
